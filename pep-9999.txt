PEP: 9999
Title: Support for indexing with keyword arguments
Version: $Revision$
Last-Modified: $Date$
Author: Stefano Borini, Jonathan Fine
Sponsor: Steven D'Aprano
Discussions-To: python-ideas@python.org
Status: Draft
Type: Standards Track
Content-Type: text/x-rst
Created: 24-Aug-2020
Python-Version: 3.10
Post-History: 
Resolution: 

Abstract
========

This PEP proposed extending python to allow keyword-like arguments to be
accepted during indexing operations. Notations in the form ``a[42, K=3, R=2]``
would become legal syntax.  A final strategy will be proposed in terms of
semantics and implementation.

This PEP is a rework and expansion of PEP 472, where an extension of the
indexing operation to support keyword arguments was analysed.Â PEP 472 was
Rejected due to apparent lack of interest back in 2019. However, renewed
interest has prompted a re-analysis and therefore this PEP.

Overview
========

Background
----------

PEP 472 was opened in 2014. The PEP focused on various use cases and was extracted
from a broad discussion on implementation strategies. The PEP was eventually rejected
in 2019 [#rejection]_ mostly due to lack of interest despite its 5 years of existence.

However, with the introduction of type hints in PEP 484 [#pep-0484]_ the
square bracket notation has been used consistently to enrich the typing
annotations, e.g. to specify a list of integers as Sequence[int]. Additionally,
there has been an expanded growth of packages for data analysis such as pandas
and xarray, which use names to describe columns in a table (pandas) or axis in
an nd-array (xarray). These packages allow users to access specific data by
names, but cannot currently use index notation ([]) for this functionality.

As a result, a renewed interest in a more flexible syntax that would allow for
named information has been expressed in many different threads.

During the investigation of PEP 472, many different strategies have been
proposed to expand the language, but no real consensus was reached. Many corner
cases have been examined more closely and felt awkward, backward incompatible
or both. Renewed interest was prompted by Caleb Donovick [#request-1]_ in 2019 
and Andras Tantos [#request-2]_ in 2020. These requests prompted a strong activity
on the python-ideas mailing list, where various options have been discussed and
a general consensus has been reached.

Use cases
---------

The following practical use cases present different cases where a keyworded
specification would improve notation and provide additional value:

1. To provide a more communicative meaning to the index, preventing e.g. accidental
   inversion of indexes

   ::

     >>> grid_position[x=3, y=5, z=8]
     >>> rain_amount[time=0:12, location=location]
     >>> matrix[row=20, col=40]
     

2. To enrich the typing notation with keywords, especially during the use of generics

   :: 

     def function(value: MyType[T=int]):


3. In some domain, such as computational physics and chemistry, the use of a
   notation such as ``Basis[Z=5]`` is a Domain Specific Language notation to represent
   a level of accuracy

   ::

     >>> low_accuracy_energy = computeEnergy(molecule, BasisSet[Z=3])

4. Pandas currently uses a notation such as

   ::
    
     >>> df[df['x'] == 1]

   which could be replaced with df[x=1].

5. xarray has named dimensions. Currently these are handled with functions .isel:

   :: 
   
     >>> data.isel(row=10)  # Returns the tenth row

   which could also be replaced with `data[row=10]`. A more complex example:

   ::

     >>> # old syntax
     >>> da.isel(space=0, time=slice(None, 2))[...] = spam  
     >>> # new syntax
     >>> da[space=0, time=:2] = spam  

   Another example:

   ::
 
     >>> # old syntax
     >>> ds["empty"].loc[dict(lon=5, lat=6)] = 10
     >>> # new syntax
     >>> ds["empty"][lon=5, lat=6] = 10

     >>> # old syntax
     >>> ds["empty"].loc[dict(lon=slice(1, 5), lat=slice(3, None))] = 10
     >>> # new syntax
     >>> ds["empty"][lon=1:5, lat=6:] = 10

It is important to note that how the notation is interpreted is up to the
implementation. This PEP only defines and dictates the behavior of python
regarding passed keyword arguments, not how these arguments should be
interpreted and used by the implementing class.

Syntax and Semantics
====================

Current status
--------------

Before attacking the problem of detailing the new syntax and semantics to the
indexing notation, it is relevant to analyse how the indexing notation works
today, in which contexts, and how it is different from a function call.

Subscripting obj[x] is, effectively, an alternate and specialised form of
function call syntax with a number of differences and restrictions compared to
obj(x). The current python syntax focuses exclusively on position to express
the index, and also contains syntactic sugar to refer to non-punctiform
selection (slices). Some common examples:

::

    >>> a[3]       # returns the fourth element of a
    >>> a[1:10:2]  # slice notation (extract a non-trivial data subset)
    >>> a[3, 2]    # multiple indexes (for multidimensional arrays)

This translates into a __(get|set|del)item__ dunder call which is passed a single
parameter containing the index (for __getitem__ and __delitem__) or two parameters
containing index and value (for __setitem__).

The behavior of the indexing call is fundamentally different from a function call
in various aspects:

The first difference is in meaning to the reader.  A function call says
"arbitrary function call potentially with side-effects". An indexing operation
says "lookup", typically to point at a subset or specific sub-aspect of an
entity (as in the case of typing notation).  This fundamental difference means
that, while we cannot prevent abuse, implementors should be aware that the
introduction of keyword arguments to alter the behavior of the lookup may
violate this intrinsic meaning.

The second difference of the indexing notation compared to a function 
is that indexing can be used for both getting and setting operations.
In python, a function cannot be on the left hand side of an assignment. In
other words, both of these are valid

   :: 

     >>> x = a[1, 2]
     >>> a[1, 2] = 5

but only the first one of these is valid

   ::

     >>> x = f(1, 2)
     >>> f(1, 2) = 5  # invalid

This asymmetry is important to understand that there is a natural imbalance
between the two forms, and therefore it is not a given that the two should
behave transparently and symmetrically. 
    
The third difference is that functions have names assigned to their
arguments, unless the passed parameters are captured with *args, in which case
they end up as entries in the args tuple. In other words, functions already
have anonymous argument semantic, exactly like the indexing operation. However,
__(get|set|del)item__ is not always receiving a tuple as the `index` argument
(to be uniform in behavior with *args).  In fact, given a trivial class:


   ::

     class X:
         def __getitem__(self, index):
             print(index)

The index operation basically forwards the content of the square brackets "as is" 
in the `index` argument:

   ::

     >>> x=X()
     >>> x[0]
     0
     >>> x[0, 1]
     (0, 1)
     >>> x[(0, 1)]
     (0, 1)
     >>> 
     >>> x[()]
     ()
     >>> x[{1, 2, 3}]
     {1, 2, 3}
     >>> x["hello"]
     hello
     >>> x["hello", "hi"]
     ('hello', 'hi')

The fourth difference is that the indexing operation knows how to convert
colon notations to slices, thanks to support from the parser. This is valid

   ::

     a[1:3]

this one isn't
  
   ::
    
     f(1:3)

The fifth difference is that there's no zero-argument form. This is valid

colon notations to slices, thanks to support from the parser. This is valid

   ::

     f()

this one isn't
  
   ::
    
     a[]
    

Compatibility Hard Points
-------------------------

Any change to the current behavior 
After discussion, it was found out that the new syntax will have a fixed set of hard points, no matter
the final implementation:

* Invoking indexing _must_ accept some object. E.g. `a[]` is still syntax error.
* It must be possible to mix single values and named indexes, e.g. `a[1, 2, foo=3]`
* No walrus allowed. E.g. `a[foo:=3] is disallowed.


New Proposal
------------

We propose to allow notations involving keyword arguments in the indexing
operation, e.g.

::

    >>> a[K=3, R=2]

which would allow a more flexible way to indicise content.

One must additionally consider the extended form that allows both positional
and keyword specification

::

    >>> a[3, R=3, K=4]


We also ensure that the current semantic for slices is applied to keyword arguments
as well. This syntax is valid:

::

    >>> a[3, R=3:10, K=4]




Alternative Syntax and Semantics (Steven's proposal)
====================================================

Steven's proposal

thing[ind1, ind2, kwd1=v1, kw2=v2] = value

Translating to:

thing.__setitem__(self, (ind1, ind2), value, kwd1=v1, kw2=v2)

which is pretty darn weird -- particularly if you try to write the handler this way:

def __setitem__(self, *args, **kwargs):

so: args would always be a 2-tuple, something like: ((ind1, ind2), value)


    def __getitem__(self, index, *, spam, eggs=None):


Is that even a question?

    obj[index, keyword=value]

where index is any comma-separated list of expressions, including
slices, keyword is an identifier, and value is any expression including
slices. Are there even any other options being considered?

A few points:

- The index is optional, but it will be a runtime TypeError if the
method isn't defined with the corresponding parameter taking a default
value.

- You can have multiple keyword=value pairs, separated by commas. They
must all follow the index part. Duplicate keywords is a runtime error,
just as they are are for function calls.

- An empty subscript remains a syntax error, even if the method
signature would allow it.

 think the simplest default value would be Ellipsis.  So foo[a=1, b=2] would be equivalent to foo[..., a=1, b=2]

But I don't see why this is a problem we have to deal with.  The index argument can just not be passed at all, and it is up to the class developer to pick an appropriate sentinel if needed.
The index argument can just not be passed at all, and it is up to the class developer to pick an appropriate sentinel if needed.
though it would be a (TypeError, rather than a SyntaxError) if no index were passed in. 

As "proper" exception handling should be close to the operation, and catch specific Exceptions, most case will probably be fine. But not all. For example, there might be code in the wild that does
try:
    a_function(something)
except TypeError:
    do_something

And there is something in a_function that uses indexing -- someone messes with that code, and puts something new in an index that used to be a SyntaxError and is now a TypeError -- in the past, that wouldn't have even run, but now it will, and the problem might not be caught in tests because the TypeError is being handled.

Given that this would be a change from a compile time error to a runtime error, there is no code that used to work that will break, but it would be easier to write broken code in certain situations -- maybe not a huge deal, but worth thinking about.




MISSING = object()

def __getitem__(self, key, x=MISSING, y=MISSING):
    if x is MISSING and y is MISSING::
        x, y = key
    if x is missing:
        x, = key
    if y is MISSING:
        y, = key

And probably that code I just wrote has bugs. And it gets more complicated if we want to have more arguments than just two. And even more complicated if we want some of the arguments to be positional only or any other combination of things. 

This is code you would not have to write if we could do this instead with a new dunder or subscript processor:

def __getx__(self, x, y): ...

And these all just work:

q[1, 2]
q[1, y=2]
q[y=2, x=1]

1 is assigned to x and 2 is assigned to y in all of these for both versions, but the second certain requires not parsing of parameters. Python does it for us. That's a lot of easily available flexibility. 


We could treat d[1, a=3] either as d[1,] + kwargs or as d[1] + kwargs. Have people debated this yet?


I don't think that anyone wants adding a keyword to a single-valued
subscript to change it to a tuple. At least, I really hope that nobody
wants this!

So given the current behaviour:

    obj[1]  # calls __getitem__(1)
    obj[1,]  # calls __getitem__((1,))

I expect that the first will be the most common. If we add a keyword to
the subscript:

    obj[1, a=3]

I would expect that the it turns into `__getitem__(1, a=3)` which is
almost surely what the reader and coder expects. It would be quite weird
for the subscript 1 to turn into a tuple just because I add a keyword.

That does leave the second case a little trickier to add a keyword to,
it would require a pair of parens to disambiguate it from above:

    obj[(1,), a=3]

but I think that's likely to be obvious to the developer who is adding
in the keyword where previously no keyword existed.


That's a fair ruling. In general, when keywords are present, the rule that you can always omit an outermost pair of parentheses is no longer true. That is, d[(...)] and d[...] are always equivalent regardless what "..." stands for, as long as (...) is a valid expression (which it isn't if there are slices involved). Example:
```
d[1]  ~~~  d[(1)]
d[1,]  ~~~  d[(1,)]
d[1, 2]  ~~~  d[(1, 2)]
```
But there is absolutely no such rule if keywords are present.

FYI, Jonathan's post (once I "got" it) led me to a new way of reasoning about the various proposals (__keyfn__, __subscript__ and what I will keep calling "Steven's proposal") based on what the compiler and interpreter need to do to support this corner case. My tentative conclusion is that Steven's proposal is superior. But I have been reviewing my reasoning and pseudo-code a few times and I'm still not happy with it, so posting it will have to wait.


What the dict class's `__getitem__` would do with that is a different issue -- probably it would be an error.


> Doesn't that mean that a "index" will not be an allowable index label, and that this conflict will depend on knowing the particular implementation details of the dunder methods?
>

Yes, that would be correct. However, the function could instead be defined as:

def __getitem__(self, index, /, **kwargs):
    ...

and then there'd be no conflict (as "self" and "index" must be passed
positionally).

Good edge case to consider. But would it really be such a problem? If you have an existing class like this:

    class C:
        def __getitem__(self, index): ...

    c = C()

then presumably calling `c[1, index=2]` would just be an error (since it would be like attempting to call the method with two values for the `index` argument), and ditto for `c[1, 2, 3, index=4]`. The only odd case might be `c[index=1]` -- but presumably that would be equivalent to `c[(), index=1]` so it would still fail.

My point is that all existing `__getitem__` implementations will raise errors if any keywords are given, even if the keyword happens to correspond to the name of the argument (say, `index`). This is to counter Chris B's concern that if an existing `__getitem__` implementation didn't use the '/' notation to indicate that `self` and `index` are positional, it would have a bug. I claim that the bug will *only* be present when someone adds keyword support to their `__getitem__` method without using the '/'. Since that's not existing code, this "proves" that adding this feature would not introduce a subtle bug in a lot of existing code -- only in carelessly written new (or updated) code.

The primary issue I was trying to find a way to reliably and clearly avoid conflicts between the index labels and the positional argument names.  So if you have:

__getitem__(self, index, **kwargs)

You can't have an index label named "index", because it conflicts with the "index" positional argument.

Apparently that isn't an issue if you structure it like this instead:

__getitem__(self, index, /, **kwargs)

But projects would need to know to do that.

> In the "New syntax", wouldn't these examples map to:
>
> d[1, 2, a=3]  =>  d.__getitem__((1, 2), a=3)
> and
> d[(1, 2), a=3]  =>  d.__getitem__((1, 2), a=3)
>
Not quite. The second should be:

d[(1, 2), a=3]  =>  d.__getitem__(((1, 2),), a=3)

   py> d = Demo()
    py> d[(1, 2)]  # Tuple single arg.
    (1, 2) <class 'tuple'>
    py> d[1, 2]  # Still a tuple.
    (1, 2) <class 'tuple'>


Adding a keyword arg should not change this.

An extra **kwds would be quite sufficient for xarray. We don't need to distinguish between `d[day=3, detector=4]` and `d[day=4, detector=3]`, at least not any differently from normal Python keyword arguments.

One question that comes up: should d[**kwargs] be valid syntax? d[*args] currently is not, but that's OK since d[tuple(args)] is identical.

On the other hand, we probably do need d[**kwargs] since there's no way to dynamically unpack keyword arguments (short of directly calling __getitem__). And perhaps for symmetry this suggests d[*args] should be valid, too, defined as equivalent to d[tuple(args)].


If d[] were to be allowed, I would expect it to pass an empty
tuple as the index, since it's the limiting case of reducing the
number of positional indices.


We have `Tuple[int, int]` as a tuple of two integers. And we have `Tuple[int]` as a tuple of one integer. And occasionally we need to spell a tuple of *no* values, since that's the type of `()`. But we currently are forced to write that as `Tuple[()]`. If we allowed `Tuple[]` that odd edge case would be removed.

So I probably would be okay with allowing `obj[]` syntactically, as long as the dict type could be made to reject it.

For what its worth, NumPy uses `None` to indicate inserting a new
axis/dimensions (we have an `np.newaxis` alias as well):

    arr = np.array(5)
    arr.ndim == 0
    arr[None].ndim == arr[None,].ndim == 1

So that would be problematic. There are two (subtly different [1])
acceptable choices for `ndarray[]`:

I think it is worth directly discussing the availability of slices in PEP 472-style keyword indices, since we seem to have mostly converged on a dunder method signature.  This is an issue that has been alluded to regarding keyword-based (labelled) indices but not directly addressed.  The basic syntax would be something like d[x=1:3].


Type hints are indeed dispatched differently, but this is done based on information that is only available at runtime. Since PEP 560, for `x[y]`, if no `__getitem__` method is found, and `x` is a type (class) object, and `x` has a class method `__class_getitem__`, that method is called. Extending this with keyword args is straightforward. Modifying the compiler to generate different bytecode for this case is essentially impossible.

See https://github.com/python/cpython/blob/6844b56176c41f0a0e25fcd4fef5463bcdbc7d7c/Objects/abstract.c#L181-L198 for the code (it's part of PyObject_GetItem).


Should
q[1, 2, k=3]
q[(1, 2), k=3]

evaluate the same way?

hat is, `d[::]` is syntactically valid, but `d[(::)]` is not. Try it.




Alternative Syntax and semantics
================================

Adding new dunders
------------------

This proposal introduces new dunders __(get|set|del)item_ex__ 
that are invoked over the __(get|set|del)item__ triad, if they are present.

The rationale around this choice is to make the intuition around how to add kwd
arg support to square brackets more obvious and in line with the function
behavior. It would also make writing code for specialized libraries that tend
to use item dunders, like pandas and xarray, much easier. Right now such
libraries have to rely on their own efforts to break up a key, or use
"functions in stead" (e.g. iloc())



Problems with this approach:

* __setitem_ex__ value would need to be the first element, because the index is of arbitrary length.
* It will slow down subscripting. For every subscript access, this new dunder
  attribute gets investigated on the class, and if it is not present then the
  default key translation function is executed. Different ideas were proposed to handle this, from wrapping the method
  only at class instantiation time (would not work when monkeypatching) 

* It adds complexity

Again, implicit on your argument here is the assumption that all keyword indices necessarily map into positional indices.  This may be the case with the use-case you had in mind.  But for other use-cases brought up so far that assumption is false.  
xarray, which is the primary python package for numpy arrays with labelled dimensions.  It supports adding and indexing by additional dimensions that don't correspond directly to the dimensions of the underlying numpy array, and those have no position to match up to.  They are called "non-dimension coordinates".

Other people have wanted to allow parameters to be added when indexing, arguments in the index that change how the indexing behaves.  These don't correspond to any dimension, either.

possibly have to invert value and index?s
lass A:
        __keyfn__ = None
        def __setitem__(self, val, x=0, y=0, z=0):
            print((val, x, y, z))

    >>> a = A()
    >>> a[1, z=2] = 'hello'
    ('hello', 1, 0, 2)*


Objection 1: Slowing Things Down

The INTENDED EFFECT of the changes to internals will be as Jonathan Fine described: every time a subscript operation occurs, this new dunder attribute gets investigated on the class, and if it is not present then the default key translation function is executed.

If things were implemented in exactly that way, obviously it would slow everything down a lot. Every subscripting operation gets slowed down everywhere and that's probably not an option. 

the new dunder is *only* effective if added at class creation time,
not if it's added later. You may not care about this, but it is a very
different behaviour than any other dunder method Python supports - so
quite apart from the problems people would have learning and
remembering that this is a special case, you have to document *in your
proposal* that you intend to allow this. And other people *do* care
about disallowing dynamic features like monkeypatching.



Adding an adapter function
--------------------------

Similar to the above, in the sense that a pre-function would be called to convert the "new style" indexing into "old style indexing" that is then passed.
Has problems similar to the above.


A single bit to change the behavior
-----------------------------------

Ricky has given some examples. Here are more, all assuming
    __keyfn__ = True

First, this use of __keyfn__ would allow
   >>> d[1, 2, z=3]
to result in
   >>> d.__getitem__(1, 2, z=3)

Some further examples:
    >>> d[1, 2]
    >>> d.__getitem__(1, 2)

    >>> d[(1, 2)]
    >>> d.__getitem__((1, 2))

    >>> d[a=1, b=2]
    >>> d.__getitem__(a=1, b=2)

I find the above easy to understand and use. For Steven's proposal the calls to __getitem__ would be

    >>> d[1, 2, z=3]
    >>> d.__getitem__((1, 2), z=3)

    >>> d[1, 2]
    >>> d.__getitem__((1, 2)

    >>> d[(1, 2)] # Same result as d[1, 2]
    >>> d.__getitem__((1, 2)) # From d[(1, 2)]

   >>> d[a=1, b=2]
    >>> d.__getitem__((), a=1, b=2)

I find these harder to understand and use, which is precisely the point Ricky made in his most recent post. That's because there's a clear and precise analogy between
    >>> x(1, 2, a=3, b=4)
    >>> x[1, 2, a=3, b=4]

I think it reasonable to argue adding a single bit to every class is not worth the benefit it provides. However, this argument should be supported by evidence. (As indeed should the argument that it is worth the benefit.)

I also think it reasonable to argue that now is not the time to allow __keyfn__ to have values other than None or True. And that allowing further values should require an additional PEP.

I don't recall seeing an argument that Steven's proposal is as easy to understand and use as mine (with __keyfn__ == None).


Yes. I find it a big flaw that the signature of __setitem__ is so strongly influenced by the value of __keyfunc__. For example, a static type checker (since PEP 484 I care deeply about those and they're popping up like mushrooms :-) would have to hard-code a special case for this, because there really is nothing else in Python where the signature of a dunder depends on the value of another dunder.

And in case you don't care about static type checkers, I think it's the same for human readers. Whenever I see a __setitem__ function I must look everywhere else in the class (and in all its base classes) for a __keyfn__ before I can understand how the __setitem__ function's signature is mapped from the d[...] notation.

Finally, I am unsure how you would deal with the difference between d[1] and d[1,], which must be preserved (for __keyfn__ = True or absent, for backwards compatibility). The bytecode compiler cannot assume to know the value of __keyfn__ (because d could be defined in another module or could be an instance of one of several classes defined in the current module). (I think this problem is also present in the __subscript__ version.)



Rejected Ideas
==============

PEP 472 presents a good amount of ideas that are now all to be considered Rejected. A personal email from D'Aprano to the Author
specifically said:

"I have now carefully read through PEP 472 in full, and I am afraid I
cannot support any of the strategies currently in the PEP."

Moreover, additional ideas and discussion occurred during the re-evaluation of the PEP:

1. create a new "kwslice" object

Has anyone suggested attaching the keyword args as attributes
on the slice object?

We'll also need to decide how to combine subscripts and keywords:

    obj[a, b:c, x=1]
    # is this a tuple argument (a, slice(b, c), key(x=1))
    # or key argument key(a, slice(b, c), x=1)

would get the job done, but requires everyone who
needs keyword arguments to parse the tuple and/or key object by hand to
extract them. Having done something similiar in the past (emulating
keyword-only arguments in Python 2), I can tell you this is painful.

It would also open up to the get/set/del function to always accept arbitrary
keyword arguments, whether they make sense or not. We want the developer
to be able to specify which arguments make sense and which ones do not.


Again, implicit on your argument here is the assumption that all keyword
indices necessarily map into positional indices.  This may be the case with the
use-case you had in mind.  But for other use-cases brought up so far that
assumption is false.  Your approach would make those use cases extremely
difficult if not impossible.

xarray, which is the primary python package for numpy arrays with labelled
dimensions.  It supports adding and indexing by additional dimensions that
don't correspond directly to the dimensions of the underlying numpy array, and
those have no position to match up to.  They are called "non-dimension
coordinates".

Other people have wanted to allow parameters to be added when indexing,
arguments in the index that change how the indexing behaves.  These don't
correspond to any dimension, either.


Adding keywords to indexation for custom classes is not
the same as modifying the standard dict type for typing.


Common objections
=================

> Just use a method call.

One of the use cases is typing, where the [] is used exclusively, and function calls are out of the question.
Moreover, function calls do not handle slice notation, which is commonly used in some cases for arrays.

One problem is type hint creation has been extended to built-ins in python 3.9, so that you do not have to import Dict, List, et al anymore.

Without kwd args inside [ ], you would not be able to do this:

Vector = dict[i=float, j=float]

...but for obvious reasons, call syntax using built ins to create custom type hints isn't an option :

dict(i=float, j=float)  # this syntax isn't available

We could treat d[1, a=3] either as d[1,] + kwargs or as d[1] + kwargs. Have people debated this yet?


I don't think that anyone wants adding a keyword to a single-valued
subscript to change it to a tuple. At least, I really hope that nobody
wants this!

So given the current behaviour:

    obj[1]  # calls __getitem__(1)
    obj[1,]  # calls __getitem__((1,))

I expect that the first will be the most common. If we add a keyword to
the subscript:

    obj[1, a=3]

I would expect that the it turns into `__getitem__(1, a=3)` which is
almost surely what the reader and coder expects. It would be quite weird
for the subscript 1 to turn into a tuple just because I add a keyword.


What I should have said was that a[1,]
would continue to create a tuple, regardless of whether old or new style
indexing was happening.


d[1] -> d.__getitem__(1)
d[1,] -> d.__getitem__((1,))
d[1, 2] -> d.__getitem__((1, 2))
d[a=3] -> d.__getitem__((), a=3)
d[1, a=3] -> d.__getitem__((1,), a=3)
d[1, 2, a=3] -> d.__getitem__((1, 2), a=3)

d[1] = val -> d.__setitem__(1, val)
d[1,] = val -> d.__setitem__((1,), val)
d[1, 2] = val -> d.__setitem__((1, 2), val)
d[a=3] = val -> d.__setitem__((), val, a=3)
d[1, a=3] = val -> d.__setitem__((1,), val, a=3)
d[1, 2, a=3] = val -> d.__setitem__((1, 2), val, a=3)

SHOULD BE:
d[1, a=3] -> d.__getitem__(1, a=3)
SHOULD BE:
d[1, a=3] = val -> d.__setitem__(1, val, a=3)



If you're worried about people doing things like

    a[1, 2, 3, value = 4] = 5

I'm not sure that's really a problem -- usually it will result in
an exception due to specifying more than one value for a parameter.





References
==========

.. [#rejection] "Rejection of PEP 472"
       (https://mail.python.org/pipermail/python-dev/2019-March/156693.html)
.. [#pep-0484] "PEP 484 -- Type hints" 
       (https://www.python.org/dev/peps/pep-0484)
.. [#request-1] "Allow kwargs in __{get|set|del}item__"
       (https://mail.python.org/archives/list/python-ideas@python.org/thread/EUGDRTRFIY36K4RM3QRR52CKCI7MIR2M/)
.. [#request-2] "PEP 472 -- Support for indexing with keyword arguments"
       (https://mail.python.org/archives/list/python-ideas@python.org/thread/6OGAFDWCXT5QVV23OZWKBY4TXGZBVYZS/)


Copyright
=========

This document has been placed in the public domain.



..
   Local Variables:
   mode: indented-text
   indent-tabs-mode: nil
   sentence-end-double-space: t
   fill-column: 70
   End:
