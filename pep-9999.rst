PEP: 9999
Title: Variadic Generics
Author: Mark Mendoza <mendoza.mark.a@gmail.com>,
        Matthew Rahtz <mrahtz@google.com>,
        Vincent Siles <vsiles@fb.com>
Sponsor: TODO
Status: Draft
Type: Standards Track
Content-Type: text/x-rst
Created: 16-Sep-2020
Python-Version: 3.10
Post-History: 07-Oct-2020

Abstract
========

PEP 484 introduced ``TypeVar``, enabling creation of generics parameterised
with a single type. In this PEP, we extend ``TypeVar`` to support parameterisation
with an *arbitrary* number of types - that is, a *variadic* type variable,
enabling *variadic* generics. This allows the type of array-like structures
in numerical computing libraries such as NumPy and TensorFlow to be
parameterised with the array *shape*, enable static type checkers
to catch shape-related bugs in code that uses these libraries.

Motivation
==========

There are three main use-cases for variadic generics.

The primary motivation is to enable typing of array shapes in numerical
computing libraries such as NumPy and TensorFlow. This is the use-case
much of the PEP will focus on.

Two [#hkt]_ additional use cases are a) typing of ``map`` and ``zip``,
and b) typing of arbitrary-length heterogeneous tuples.

We discuss each of these three motivations below.

Array Shapes
-------------

In the context of numerical computation with libraries such as NumPy and
TensorFlow, the *shape* of arguments is often just as important as the
argument *type*. For example, consider the following function which converts a
batch [#batch]_ of videos to grayscale:

::

    def to_gray(videos: Tensor): ...

From the signature alone, it is not obvious what shape of array [#array]_
we should pass for the ``videos_batch`` argument. Possibilities include, for
example,

  batch × time × height × width × channels

and

  time × batch × channels × height × width. [#timebatch]_

Ideally, we should have some way of making the required shape clear in the
signature itself. Multiple proposals [#numeric-stack]_ [#typing-ideas]_
[#syntax-proposal]_ have suggested the use of the standard generics syntax for
this purpose. We would write:

::

    def to_gray(videos: Tensor[Time, Batch, Height, Width, Channels]): ...

However, note that arrays can be of arbitrary rank - ``Tensor`` as used above is
generic in an arbitrary number of axes. One way around this would be to use a different
``Tensor`` class for each rank...

::

    Axis1 = TypeVar('Axis1')
    Axis2 = TypeVar('Axis2')

    class Tensor1(Generic[Axis1]): ...

    class Tensor2(Generic[Axis1, Axis2]): ...

...but this would be cumbersome, both for users (who would have to sprinkle 1s and 2s
and so on throughout their code) and for the authors of tensor libraries (who would have to duplicate implementations throughout multiple classes).

Variadic generics are necessary for a ``Tensor`` that is generic in an arbitrary
number of axes to be cleanly defined as a single class.

``map`` and ``zip``
-------------------

PEP 612 [#pep-612]_ introduced ``ParamSpec``, enabling parameter types of one
callable to be forwarded to another callable. However, in many cases we actually
wish to *transform* parameter types before using them elsewhere in the
signature.

Consider, for example, the signature of ``map`` for a particular choice of
function and iterables:

::

    def func(int, str) -> float: ...
    iter1: List[int]
    iter2: List[str]

    def map(func: Callable[[int, str], float],
            iter1: Iterable[int],
            iter2: Iterable[str]) -> Iterable[float]: ...

Note that the number of iterables passed to ``map`` is dependent
on the supplied function, and that the types of those iterables
must correspond to the types of supplied function's arguments.

A similar example is ``zip``:

::

    iter1: List[int]
    iter2: List[str]

    def zip(iter1: Iterable[int],
            iter2: Iterable[str]) -> Iterable[Tuple[int, str]]: ...

Neither of these signatures can be specified in the general case using
existing typing mechanisms. The signature of ``zip``, for example, is
currently specified [#zip-sig]_ with a number of overloads.

Arbitrary-length Heterogeneous Tuples
-------------------------------------

PEP 484 [#pep-484]_ allows us to type *heterogeneous* tuples of *fixed*
length...

::

    def foo() -> Tuple[int, str]:
      return (1, 'a')

...and *homogenous* tuples of *arbitrary* length...

::

    def f(t: Tuple[int, ...]) -> Tuple[int, ...]:

    f((1, 2))     # Valid; inferred type is Tuple[int, int]
    f((1, 2, 3))  # Also valid

...but not *heterogeneous* tuples of *arbitrary* length:

::

    def identity(t: Tuple):
      return t

    f((1, 'a'))[0]  # Should be inferred as int
    f((1, 'a'))[1]  # Should be inferred as str
    # Etc. for other tuples of arbitrary types and arbitrary length

Again, the signature of ``identity`` here cannot be specified using existing
typing mechanisms.

Specification
=============

In order to support the above use-cases, we introduce:

* A new argument to ``TypeVar``, `list`, that specifies that the ``TypeVar``
  acts as a placeholder not for a single type but for an arbitrary
  *list* of types (which we will refer to as a "type list variable").
* A new syntax for parameterizing generic functions and classes using a
  type list variable.
* Two new type operators, ``Apply`` and ``Map``.

These are described in detail below.

Type List Variables
-------------------

In the same way that a normal type variable is a stand-in for a single type,
a type *list* variable is a stand-in for an arbitrary number of types in a flat
ordered list.

Type list variables are created with:

::

    from typing import TypeVar

    Ts = TypeVar('Ts', list=True)

A type list variable behaves in a similar way to a parameterized ``Tuple``.
For example, in a generic object instantiated with type parameters
``int`` and ``str``,  ``Ts`` behaves similarly to ``Tuple[int, str]``.

Parameterizing Types: Star Operator
'''''''''''''''''''''''''''''''''''

One use of type list variables are to parameterize variadic types
such as ``Tuple``.

To differentiate type list variables from normal type variables, we introduce
a new use for the star operator:

::

    Tuple[*Ts]

The star operator here serves to 'expand' the type list into
its component types. For example, in a generic object instantiated
with ``Ts`` being ``int`` and ``str``, then ``Tuple[*Ts]`` would
be equivalent to ``Tuple[int, str]``.

In its new use, the star operator can be applied to either a type list
variable or a parameterised ``Tuple``:

::

    Ts = TypeVar('Ts', list=True)

    Tuple[*Ts]  # Valid
    Tuple[*Tuple[int, str]]  # Also valid

Expanded type list variables can also be mixed with concrete types:

::

    Tuple[int, *Ts]

Here, if ``Ts`` were ``int`` and `str``, ``Tuple[int, *Ts]`` would be
``Tuple[int, int, str]``.

Parameterizing Types: ``Expand``
'''''''''''''''''''''''''''''''

Because the new use of the star operator requires a syntax change and is
therefore incompatible with previous versions of Python, we also introduce the
``Expand`` type operator for use in existing versions of Python. ``Expand``
behaves identically to the star operator, but without requiring a syntax change:

::

    from typing import Expand

    Tuple[Expand[Ts]]              # Equivalent to Tuple[*Ts]
    Tuple[Expand[Tuple[int, str]]  # Equivalent to Tuple[*Tuple[int, str]]

As with the star operator, usages of ``Expand`` can also be mixed with
concrete types:

::

    Tuple[int, Expand[Ts]]  # Equivalent to Tuple[int, *Ts]

Type Variables Must be Expanded
'''''''''''''''''''''''''''''''

Note that when an instance of a type list variable is used as a type parameter,
it *must* be used in conjunction with the star or ``Expand`` operator:

::

    Tuple[Ts]  # NOT valid

Parameterizing Function Signatures and Classes
''''''''''''''''''''''''''''''''''''''''''''''

Type list variables can be used anywhere a normal ``TypeVar`` can. For example,
in function signatures:

::

    def identity(x: Tuple[*Ts]) -> Tuple[*Ts]: ...

    identity((1, 'a'))  # Inferred type is Tuple[str, int]

And in classes and methods:

::

    Shape = TypeVar('Shape', list=True)

    class Tensor(Generic[*Shape]):

        def __abs__(self) -> Tensor[*Shape]: ...

    class Height: pass
    class Width: pass
    x: Tensor[Height, Width] = Tensor()
    y = abs(x)                           # Inferred type is Tensor[Height, Width]

``*args`` as a Type List Variable
'''''''''''''''''''''''''''''''''

PEP 484 states that when a type annotation is provided for ``*args``, each argument
must be of the type annotated. That is, if we specify ``*args`` to be type ``int``,
then *all* arguments must be of type ``int``. This limits our ability to specify
the type signatures of functions that take heterogeneous argument types.

If ``*args`` is annotated as being a type list variable, however, the
types of the individual arguments become the types in the type list:

::
    
    def args_to_tuple(*args: *Ts) -> Tuple[*Ts]: ...
    # Equivalent:
    def args_to_tuple(*args: Expand[Ts]) -> Tuple[Expand[Ts]]: ...

    args_to_tuple(1, 'a')  # Inferred type is Tuple[int, str]

Inside the body of ``args_to_tuple``, the type of ``args`` is simply ``Ts``. At
runtime, ``Ts`` is replaced with a ``Tuple`` parameterised by the types of the
individual arguments.

Again, note that when a type list variable is used in this way, it
*must* be in conjunction with the star or ``Expand`` operator:

::

    def foo(*args: Ts): ...  # NOT valid

Also note that a type list variance may *not* be used as the type of
``**kwargs``. (We do not yet know of a use-case for this feature, so prefer
to leave the ground fresh for a potential future PEP.)

::

    def foo(**kwargs: *Ts): ...  # NOT valid


Not Yet Supported: Type Bounds
''''''''''''''''''''''''''''''

Normally, ``TypeVar`` can also take a ``bound`` argument,
that constrains the type to a subtype of the type specified.

As of this PEP, the ``bound`` argument is not supported when the ``list``
argument is also specified. (Again, we are not yet sure of a use-case
for this feature, so prefer to leave it unspecified until we
have a better idea of how it should work.)
    
Not Yet Supported: Variance
'''''''''''''''''''''''''''

Consider a type ``Animal`` and a subclass ``Cat``. A generic ``Foo`` is *covariant* in
its type parameter if ``Foo[Cat]`` is considered a subclass of ``Foo[Animal]``.
Conversely, ``Foo`` is *contravariant* in its type if ``Foo[Animal]`` is a subclass of
``Foo[Cat]``. If there is no subclass relationship between ``Foo[Animal]`` and ``Foo[Cat]`` at all, then `Foo` is *invariant* in its type.

Again, because we do not yet know of a use case for variance relationships
of type list variables and prefer to leave the ground fresh for the future,
type list variables as defined in this PEP are always *invariant*. That is,
given a generic type ``Foo[*Ts]``, ``Foo[Animal, Cat]`` has no subclass
relationship to ``Foo[Animal, Animal]``.

``Map``
-------

To enable typing of functions such as ``map`` and ``zip``, we introduce the
``Map`` type operator. Not to be confused with the existing operator
``typing.Mapping``, ``Map`` is analogous to ``map``, but for types:

::

    from typing import Map

    def args_to_tuples(*args: Ts) -> Map[Tuple, Ts]: ...

    args_to_tuples(1, 'a')  # Inferred type is Tuple[Tuple[int], Tuple[str]]

``Map`` takes two operands. The first operand is a parameterizable
type (or type alias [#type_aliases]) such as ``Tuple`` or ``List``. The second operand
is a type list variable or a parameterized ``Tuple`` such as ``Tuple[int, str]``.
The result of ``Map`` is a ``Tuple``, where the Nth type in the ``Tuple`` is the
first operand parameterized by the Nth type in the second operand.

Because ``Map`` returns a parameterized ``Tuple``, it can be used anywhere
that a type list variable would be. For example:

::
    
    # Effectively the same as 'arg1: List[T1], arg2: List[T2], ...'
    def foo(*args: *Map[List, Ts]): ...

    # Same as '-> Tuple[List[T1], List[T2], ...]'
    def bar(*args: *Ts) -> Map[List, Ts]: ...

    bar()        # Inferred type is Tuple[()] (an empty tuple)
    bar(1)       # Inferred type is Tuple[List[int]]
    bar(1, 'a')  # Inferred type is Tuple[List[int], List[str]]

``map`` and ``zip``
'''''''''''''''''''

``Map`` allows us to specify the signature of ``map`` as:

::

    ArgTs = TypeVar('ArgTs', list=True)
    ReturnT = TypeVar('ReturnT')

    def map(func: Callable[[*ArgTs], ReturnT],
            *iterables: *Map[Iterable, ArgTs]) -> Iterable[ReturnT]: ...

    def func(int, str) -> float: ...
    # ArgTs is Tuple[int, str]
    # Map[Iterable, ArgTs] is Iterable[int], Iterable[str]
    # Therefore, iter1 must be type Iterable[int],
    #        and iter2 must be type Iterable[str]
    map(func, iter1, iter2)

Similarly, we can specify the signature of ``zip`` as:

::

    def zip(*iterables: *Map[Iterable, ArgTs]) -> Iterable[*ArgTs]): ...

    l1: List[int]
    l2: List[str]
    zip(l1, l2)  # Iterable[int, str]

Nesting
'''''''

Because the type of the result of ``Map`` is the same as the type of its second
operand, the result of one ``Map`` *can* be used as the input to another ``Map``:

::

    Map[Tuple, *Map[Tuple, Ts]]  # Valid!

Accessing Individual Types
--------------------------

``Map`` allows us to operate on types in a bulk fashion. For situations where we
require access to each individual type, overloads can be used with individual
``TypeVar`` instances in place of the type list variable:

::

    Shape = TypeVar('Shape', list=True)
    Axis1 = TypeVar('Axis1')
    Axis2 = TypeVar('Axis2')
    Axis3 = TypeVar('Axis3')

    class Tensor(Generic[*Shape): ...

    @overload
    class Tensor(Generic[Axis1, Axis2]):

      def transpose(self) -> Tensor[Axis2, Axis1]: ...

    @overload
    class Tensor(Generic[Axis1, Axis2, Axis3]):

      def transpose(self) -> Tensor[Axis3, Axis2, Axis1]: ...

Concatenating Other Types to a Type List Variable
-------------------------------------------------

If a type list variable appears with other types in the same type parameter
list, the effect is to concatenate those types with the types
in the type list variable:

::

    Shape = TypeVar('Shape', list=True)
    class Batch: pass
    class Height: pass
    class Width: pass

    class Tensor(Generic[*Shape]): ...

    def add_batch(x: Tensor[*Shape]) -> Tensor[Batch, *Shape]: ...
    def add_batch_compat(x: Tensor[Expand[Shape]]) -> Tensor[Batch, Expand[Shape]]: ...

    x: Tensor[Height, Width]
    add_batch(x)  # Inferred type is Tensor[Batch, Height, Width]

A single type list variable can also be combined with regular ``TypeVar`` instances:

::

    T1 = TypeVar('T1')
    T2 = TypeVar('T2')

    class Foo(Generic[T1, T2, *Ts]): ...

    foo: Foo[int, str, bool, float]  # T1=int, T2=str, Ts=(bool, float]

However, at most one type list variable can appear in a parameter list - see
`Multiple Type List Variable Parameters`_ below for details.

::

    Ts1 = TypeVar('Ts1', list=True)
    Ts2 = TypeVar('Ts2', list=True)

    # NOT allowed
    class Bar(Generic[*Ts1, *Ts2]):
      ...

Rationale and Rejected Ideas
============================

Supporting Variadicity Through aliases
--------------------------------------

As noted in the introduction, it **is** possible to avoid variadic generics
by simply defining aliases for each possible number of type parameters:

::

    class Tensor1(Generic[Axis1]): ...
    class Tensor2(Generic[Axis1, Axis2]): ...

However, this seems somewhat clumsy - it requires users to unnecessarily
pepper their code with 1s, 2s, and so on for each rank necessary.

Naming of ``Map``
-----------------

One downside to the name ``Map`` is that it might suggest a hash map. We
considered a number of different options for the name of this operator.

* ``ForEach``. This is rather long, and we thought might imply a side-effect.
* ``Transform``. The meaning of this isn't obvious enough at first glance.
* ``Apply``. This is inconsistent with ``apply``, an older Python function
  which enabled conversion of iterables to arguments before the star
  operator was introduced.

In the end, we decided that ``Map`` was good enough.

Multiple Type List Variable Parameters
--------------------------------------

As of this PEP, a maximum of one type list variable can appear in a
type parameter list:

::

    Ts1 = TypeVar('Ts1', list=True)
    Ts2 = TypeVar('Ts2', list=True)

    # NOT allowed
    class Foo(Generic[*Ts1, *Ts2]): ...

We decided to disallow this because it introduces considerable
extra complexity. To understand why, consider the instantiation
of the above class:

::

    foo: Foo[str, int float]

How should we decide which types map to which type list variable? The expression
is ambiguous, and we would instead need to introduce double square brackets:

::

    foo: Foo[[str, int], [float]]

Under which conditions should double square brackets be allowed? Should
the number and position of double square brackets match the number and position
of type list variable? But then consider the following example using
structural subtyping:

::

    from typing import Protocol

    class SupportsFoo(Protocol, Generic[*Ts1, *Ts2]):
      def foo(self) -> Tuple[*Ts1, *Ts2]: ...

    class X:
      def foo(self) -> Tuple[int, str, bool]: ...

By structural subtyping, ``X`` is implicitly a subtype of ``SupportsFoo``.
However, again, there is ambiguity: is it a subclass of
``SupportsFoo[[int], [str, bool]]``, or of ``SupportsFoo[[int, str], [bool]]``?

Again, we could use double brackets to disambiguate this, but this would
be problematic for two reasons:

* It would be confusing because there is no obvious link between ``X``.
  ``SupportsFoo``; they could be in completely different modules, or
  even different packages. If a reader comes across an extra pair of square
  brackets in the definition of ``X``, how is she supposed to know what they're
  there for?
* Because a static checker cannot be expected to know of all possible
  protocols ahead of time, there is no way to check whether the placement
  of the square brackets matches to those of type list variables -
  so the only possible solution seems to be to allow double square
  brackets in arbitrary locations, which seems like a terrible thing.

Perhaps this can be fixed by disallowing multiple type list variables only
in the case of ``Protocol``, but this seems somewhat ad-hoc. In any case,
we leave this functionality to a future PEP if it turns out to have
an important use-case.

Accessing Individual Types Without Overloads
--------------------------------------------

We chose to support access to individual types in the type list variable
using overloads (see the `Accessing Individual Types`_ section). One
alternative would have been to allow explicit access to arbitrary parts
of the type list variable - for example, through indexing:

::

    def foo(t: Tuple[Ts]): 
      x: Ts[1] = t[1]

We decided to omit this mechanism from this PEP because a) it adds complexity,
b) we were not aware of any use-cases that need it, and c) if it turns out to be
needed in the future, it can easily be added in a future PEP.

Integer Generics
----------------

Consider a function such as `np.tile`:

::

   x = np.zeros((3,))      # A tensor of length 3
   y = np.tile(x, reps=2)  # y is now length 6

Intuitively, we would specify the signature of such a function as:

::

    @overload
    def tile(A: Tensor[N], reps: Literal[2]) -> Tensor[2*N]: ...
    # ...and other overloads for different values of `reps`

``N`` is *sort* of like a type variable. However, type variables
stand in for *types*, whereas here we want ``N`` to stand in for a
particular *value*. ``N`` should be some sort of 'integer type variable'.

(Note that ``N`` could *not* be created as simply ``TypeVar('N', bound=int)``.
This would state that ``N`` could stand for an ``int`` or any *subtype* of ``int``.
For our signature above, we would need ``N`` to stand for any *instance* of
type ``int``.)

We decided to omit integer type variables for this PEP, postponing it for a future
PEP when necessary.

Integer Parameterization
------------------------

The examples of this PEP have parameterised tensor types
using the semantic meaning of each axes, e.g. ``Tensor[Batch, Time]``.
However, we may also wish to parameterize using the actual
integer value of each part of the shape, such as ``Tensor[Literal[64], Literal[64]]``.

There are two aspects related to such integer parameterization that we decided
to ignore in this PEP:

**Examples of integer parameterization**. Thought it clearly *is* valid to
parameterize with literal types, we wish to encourage the use of semantic
labelling of tensor axes wherever possible: having each axis labelled serves
as extra protection against mistakes when manipulating axes.

**Syntactic sugar for integer parameterization**. Typing ``Literal`` is
cumbersome; ideally, we could write ``Tensor[64, 64]`` as syntactic sugar
for ``Tensor[Literal[64], Literal[64]]``. However, this would require an
inconsistency: because of forward referencing, ``Tensor['Batch']`` and
``Tensor[Literal['Batch']]`` mean different things. For this to work, we
would have to stipulate this sugar only applies for integers. We leave
this discussion for a future PEP. (If you do wish to employ such types
in your code currently, we recommend ``import Typing.Literal as L``
enabling the much shorter ``L[64]``.)

Checking the Number of Types in a Variadic Generic
--------------------------------------------------

Consider reduction operations, which behave as:

::

   x = np.zeros((2, 3, 5))
   reduce_sum(x, axis=0)    # Shape (3, 5)
   reduce_sum(x, axis=1)    # Shape (2, 5)

To compactly specify the signature of these operations, we would ideally
be able to write something like:

::

    Shape = TypeVar('Shape', list=True)

    # Tensor of rank N goes in, tensor of rank N-1 comes out
    def reduce_sum(x: Tensor[Shape[N]], axis: int) -> Tensor[Shape[N-1]]: ...

``Shape[N]`` here states that number of types in ``Shapes`` is bound to ``N``,
where ``N`` is some object that we can perform arithmetic on.

Lacking an urgent use-case for this feature, we omit it from this PEP,
leaving it to a future PEP if necessary. In the meantime, such functions
can still be typed using overloads:

::

    @overload
    def reduce_sum(x: Tensor[A, B], axis: Literal[0]) -> Tensor[B]: ...

    @overload
    def reduce_sum(x: Tensor[A, B], axis: Literal[1]) -> Tensor[A]: ...

    ...

Backwards Compatibility
=======================

TODO

* ``Tuple`` needs to be upgraded to support parameterization with a
  a type list variable.


Reference Implementation
========================

TODO

Appendix: Variadic Generics in Typed Scheme
===========================================

In this section we briefly illustrate how variadic generics work in another
language, Typed Scheme. [#typed_scheme]_

Syntax: Uniform Types
---------------------

Typed Scheme uses a different syntax for variadic generics depending on
whether all the types are the same. If all the types *are* the same,
variadicity of an argument is simply denoted with a star:

::
    
    (: list
      (All(A)
        (A* -> (Listof A))
      )
    )

In prose, this type definition states:

    'list' is a function which takes an arbitrary number of arguments of
    type A, and returns a list of type A, where A can be any type.

This is equivalent to the following Python:

::

    A = TypeVar('A')
    def list(*args: A) -> List[A]: ...

Syntax: Non-Uniform Types
-------------------------

If the types are *not* all the same, a different syntax is used:

::
    
    (: map
      (All(C A B...) (
        (A B...B -> C) (Listof A) (Listof B)...B -> (Listof C)
      ))
    )

In prose:

    'map' is a function. The first argument to 'map' is a function
    which takes a first argument of type A along with an arbitrary number
    remaining arguments of arbitrary types B..., and returns type C. The second
    argument to 'map' is a list of type A. The remaining arguments to map
    are an arbitrary number of lists of arbitrary types B.... 'map' returns
    a list of type C. All this is true for all types A, B and C.

In this syntax, variadicity is implemented with ``...``. The ``...`` syntax is
used in two different ways:

* In the ``All`` *type constructor*, ``B...`` indicates that ``B`` stands for
  an arbitrary number of types elsewhere in the type definition.

* In the ``All`` *body*, ``Expression...B`` indicates that ``Expression``
  should be copied as many times as there are arguments, with ``B`` in
  each expression replaced with the type of the corresponding argument.
  For example, if the arguments were of type ``Integer`` and ``String``,
  ``B...B`` would be replaced with ``Integer String``, and
  ``(Listof B)...B`` would be replaced with
  ``(Listof Integer) (Listof String)``.

The equivalent Python as per this PEP would be:

::

    A = TypeVar('A')
    B = TypeVar('B', list=True)
    C = TypeVar('C')

    def map(func: Callable[[A, B], C],
            list1: List[A], *lists: Map[List, B]) -> List[C]: ...

Challenges in Typed Scheme
--------------------------

One challenge that arises in Typed Scheme is how to combine list processing
functions with variadic arguments.

Variadic arguments in Typed Scheme behave like lists, so intuitively,
we should expect to be able to use functions such as ``map`` on variadic
arguments. However, we may also wish to use the result of such operations
as the *inputs* to other variadic functions.

The issue is that list processing functions typically return simple list
types. List types are much less expressive than the ``...`` syntax used
to specify the types of variadic arguments: for example, list types
do not encode length, while the ``...`` syntax does.

To work around this, Typed Scheme uses special rules for determining the
type of the result of ``map``. When ``map`` is called on a variadic argument
of type ``T...A`` with function ``(T -> S)``, ``map`` returns type ``S...A``.

For example, consider a variadic argument list ``(Listof A)...A)``. The concrete
types might therefore be, say, ``(Listof Integer) (Listof String)``. Suppose ``map``
is called with this variadic argument and the function ``car``, which returns the
first element of a list and therefore has signature ``((Listof A) -> A)``.
The result would be a list of length two, where the first element is an ``Integer``
and the second element is a ``String``. We can not specify the type of such a
result using ``Listof``. Instead, the special rule applies, and the result is
actually ``A...A``.


Comparison to the Proposed Python Syntax
----------------------------------------

TODO not sure this is right
Typed Scheme's way of specifying the type of non-uniform variadic argument lists
is somewhat more flexible than that proposed in this PEP. The ``...`` syntax
allows arbitrary expressions to be parameterized with the type of each argument,
whereas this PEP only allows parameterization of an arbitrary expressions with
the type of each argument rather than only singly-parameterizable types such
as ``List`` in the case of this PEP. For example, adopting the Scheme syntax
in Python would allow us to write signatures such as:

::

    Ts = TypeVar('Ts', list=True)

    def f(*args: B) -> Tuple[Union[int, B]...B]: ...
     
For arguments of type ``float`` and ``str``, the resulting type would be 
``Tuple[Union[int, float], Union[int, str]]``.

However, it is not clear whether this extra flexibility is necessary; pending
specific use-cases, we leave this for a future PEP.


Footnotes
==========

.. [#hkt] A third potential use is in enabling higher-kinded types that take
          an arbitrary number of type operands, but we do not discuss this use
          here.

.. [#batch] 'Batch' is machine learning parlance for 'a number of'.

.. [#array] We use the term 'array' to refer to a matrix with an arbitrary
   number of dimensions. In NumPy, the corresponding class is the ``ndarray``;
   in TensorFlow, the ``Tensor``; and so on.

.. [#timebatch] If the shape begins with 'batch × time', then
   ``videos_batch[0][1]`` would select the second frame of the first video. If the
   shape begins with 'time × batch', then ``videos_batch[1][0]`` would select the
   same frame.

.. [#kwargs] In the case of ``**kwargs``, we mean the Nth argument as
   it appears in the function *definition*, *not* the Nth keyword argument
   specified in the function *call*.

.. [#type_aliases] For example, in ``asyncio`` [#asyncio], it is convenient to define
   a type alias
   ``_FutureT = Union[Future[_T], Generator[Any, None, _T], Awaitable[_T]]``.
   We should also be able to apply ``Map`` to alias - e.g. ``Map[_FutureT, Ts]``.

References
==========

.. [#pep-612] PEP 612, "Parameter Specification Variables":
   https://www.python.org/dev/peps/pep-0612

.. [#pep-484] PEP 484, "Type Hints":
   https://www.python.org/dev/peps/pep-0484

.. [#numeric-stack] Static typing of Python numeric stack:
   https://paper.dropbox.com/doc/Static-typing-of-Python-numeric-stack-summary-6ZQzTkgN6e0oXko8fEWwN

.. [#typing-ideas] Ideas for array shape typing in Python: https://docs.google.com/document/d/1vpMse4c6DrWH5rq2tQSx3qwP_m_0lyn-Ij4WHqQqRHY/edit

.. [#syntax-proposal] Shape annotation syntax proposal:
   https://docs.google.com/document/d/1But-hjet8-djv519HEKvBN6Ik2lW3yu0ojZo6pG9osY/edit

.. [#zip-sig] ``typeshed/builtins.pyi``: https://github.com/python/typeshed/blob/27dfbf68aaffab4f1ded7dc1b96f6f82f536a09d/stdlib/2and3/builtins.pyi#L1710-L1733

.. [#asyncio] https://github.com/python/typeshed/blob/193c7cb93283ad4ca2a65df74c565e56bfe72b7e/stdlib/3/asyncio/tasks.pyi#L45-L154

.. [#typed_scheme] "Practical Variable-Arity Polymorphism":
   https://www2.ccs.neu.edu/racket/pubs/esop09-sthf.pdf


Acknowledgements
================

Thank you to **Alfonso Castaño**, **Antoine Pitrou**, **Bas v.B.**, **Dimitris Vardoulakis**, **Guido van Rossum**, **Jia Chen**, **Nikita Sobolev**, **Pradeep Srinivasan**, **Rebecca Chen**, **Sergei Lebedev** and **Vladimir Mikulik**
for helpful feedback and suggestions on drafts of this PEP.

Resources
=========

Discussions on variadic generics in Python started in 2016 with `Issue 193`__
on the python/typing GitHub repository.

__ https://github.com/python/typing/issues/193

Inspired by this discussion, **Ivan Levkivskyi** made a concrete proposal
at PyCon 2019, summarised in `Type system improvements`__
and `Static typing of Python numeric stack`__.

__ https://paper.dropbox.com/doc/Type-system-improvements-HHOkniMG9WcCgS0LzXZAe

__ https://paper.dropbox.com/doc/Static-typing-of-Python-numeric-stack-summary-6ZQzTkgN6e0oXko8fEWwN

Expanding on these ideas, **Mark Mendoza** and **Vincent Siles** gave a presentation on
`Variadic Type Variables for Decorators and Tensors`__ at the 2019 Python
Typing Summit.

__ https://github.com/facebook/pyre-check/blob/ae85c0c6e99e3bbfc92ec55104bfdc5b9b3097b2/docs/Variadic_Type_Variables_for_Decorators_and_Tensors.pdf

Copyright
=========

This document is placed in the public domain or under the
CC0-1.0-Universal license, whichever is more permissive.


..
   Local Variables:
   mode: indented-text
   indent-tabs-mode: nil
   sentence-end-double-space: t
   fill-column: 70
   coding: utf-8
   End:

