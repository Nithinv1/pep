PEP: 683
Title: Immortal Objects, Using a Fixed Refcount
Author: Eric Snow <ericsnowcurrently@gmail.com>, Eddie Elizondo <eduardo.elizondorueda@gmail.com>
Discussions-To: https://mail.python.org/archives/list/python-dev@python.org/thread/TPLEYDCXFQ4AMTW6F6OQFINSIFYBRFCR/
Status: Draft
Type: Standards Track
Content-Type: text/x-rst
Created: 10-Feb-2022
Python-Version: 3.11
Post-History: 15-Feb-2022
Resolution:


Abstract
========

Currently the CPython runtime maintains a
`small amount of mutable state <Runtime Object State_>`_ in the
allocated memory of each object.  Because of this, otherwise immutable
objects are actually mutable.  This can have a large negative impact
on CPU and memory performance, especially for approaches to increasing
Python's scalability.  The solution proposed here provides a way
to mark an object as one for which that per-object
runtime state should not change.

Specifically, if an object's refcount matches a very specific value
(defined below) then that object is treated as "immortal".  If an object
is immortal then its refcount will never be modified by ``Py_INCREF()``,
etc.  Consequently, the refcount will never reach 0, so that object will
never be cleaned up (unless explicitly done, e.g. during runtime
finalization).  Additionally, all other per-object runtime state
for an immortal object will be considered immutable.

This approach has some possible negative impact, which is explained
below, along with mitigations.  The fundamental improvement is that
now an object can be truly immutable.

(This proposal is meant to be CPython-specific and to affect only
internal implementation details.  There are some slight exceptions
to that which are explained below.  See `scope`_.)


Motivation
==========

As noted above, currently all objects are effectively mutable.  That
includes "immutable" objects like ``str`` instances.  This is because
every object's refcount is frequently modified as the object is used
during execution.  This is especially significant for a number of
commonly used global (builtin) objects, e.g. ``None``.  Such objects
are used a lot, both in Python code and internally.  That adds up to
a consistent high volume of refcount changes.

The effective mutability of all Python objects has a concrete impact
on parts of the Python community, e.g. projects that aim for
scalability like Instragram or the effort to make the GIL
per-interpreter.  Below we describe several ways in which refcount
modification has a real negative effect on such projects.
None of that would happen for objects that are truly immutable.

Reducing CPU Cache Invalidation
-------------------------------

Every modification of a refcount causes the corresponding CPU cache
line to be invalidated.  This has a number of effects.

For one, the write must be propagated to other cache levels
and to main memory.  This has small effect on all Python programs.
Immortal objects would provide a slight relief in that regard.

On top of that, multi-core applications pay a price.  If two threads
are interacting with the same object (e.g. ``None``)  then they will
end up invalidating each other's caches with each incref and decref.
This is true even for otherwise immutable objects like ``True``,
``0``, and ``str`` instances.  This is also true even with
the GIL, though the impact is smaller.

..
    > This looks out of context. Python has a per-process GIL. It should it go
    > after the next section.
    
    This isn't about a data race.  I'm talking about how if an object is
    active in two different threads (on distinct cores) then incref/decref
    in one thread will invalidate the cache (line) in the other thread.
    The only impact of the GIL in this case is that the two threads aren't
    running simultaneously and the cache invalidation on the idle thread
    has less impact.

..
    > This is also true even with the GIL, though the impact is smaller.
    
    Smaller than what? The baseline for that comparison is a hypothetical
    GIL-less interpreter, which is only introduced in the next section.
    Perhaps say something like "Python's GIL helps avoid this effect, but
    doesn't eliminate it."

Avoiding Data Races
-------------------

Speaking of multi-core, we are considering making the GIL
a per-interpreter lock, which would enable true multi-core parallelism.
Among other things, the GIL currently protects against races between
multiple concurrent threads that may incref or decref the same object.
Without a shared GIL, two running interpreters could not safely share
any objects, even otherwise immutable ones like ``None``.

This means that, to have a per-interpreter GIL, each interpreter must
have its own copy of *every* object.  That includes the singletons and
static types.  We have a viable strategy for that but it will require
a meaningful amount of extra effort and extra complexity.

The alternative is to ensure that all shared objects are truly immutable.
There would be no races because there would be no modification.  This
is something that the immortality proposed here would enable for
otherwise immutable objects.  With immortal objects,
support for a per-interpreter GIL
becomes much simpler.

..
    >>> Weren't you planning a PEP on subinterpreter GIL as well? Do you want to
    >>> submit them together?
    >>
    >> IMO, as it is, the PEP's motivation doesn't really stand on its own.
    >> It's only worth it as a step towards per-interpreter GIL.
    >>
    >> I'd have to think about that.  The other PEP I'm writing for
    >> per-interpreter GIL doesn't require immortal objects.  They just
    >> simplify a number of things.  That's my motivation for writing this
    >> PEP, in fact. :)
    >
    > Please think about it.
    > If you removed the benefits for per-interpreter GIL, the motivation
    > section would be reduced to is memory savings for fork/CoW. (And lots of
    > performance improvements that are great in theory but sum up to a 4% loss.)
    
    Sounds good.  Would this involve more than a note at the top of the PEP?
    
    And just to be clear, I don't think the fate of a per-interpreter GIL
    PEP should not depend on this one.

Avoiding Copy-on-Write
----------------------

For some applications it makes sense to get the application into
a desired initial state and then fork the process for each worker.
This can result in a large performance improvement, especially
memory usage.  Several enterprise Python users (e.g. Instagram,
YouTube) have taken advantage of this.  However, the above
refcount semantics drastically reduce the benefits and
has led to some sub-optimal workarounds.

Also note that "fork" isn't the only operating system mechanism
that uses copy-on-write semantics.  Anything that uses ``mmap``
relies on copy-on-write, including sharing data from shared objects
files between processes.

..
    > Anyway, I don't believe stopping refcounting will fix the CoW issue
    > yet. See this article [1] again.
    >
    > [1] https://instagram-engineering.com/dismissing-python-garbage-collection-at-instagram-4dca40b29172
    
    That's definitely an important point, given that the main objective of
    the proposal is to allow disabling mutation of runtime-internal object
    state so that some objects can be made truly immutable.
    
    I'm sure Eddie has some good insight on the matter (and may have even
    been involved in writing that article).  Eddie?
    
    > Note that they failed to fix CoW by stopping refcounting code objects! (*)
    > Most CoW was caused by cyclic GC and finalization caused most CoW.
    
    That's a good observation!
    
    > (*) It is not surprising to me because eval loop don't incre/decref
    > most code attributes. They borrow reference from the code object.
    
    +1
    
    > So we need a sample application and profile it, before saying it fixes CoW.
    > Could you provide some data, or drop the CoW issue from this PEP until
    > it is proved?
    
    We'll look into that.


Rationale
=========

The proposed solution is obvious enough that both of this proposal's
authors came to the same conclusion (and implementation, more or less)
independently.  The Pyston project `uses a similar approach <Pyston_>`_.
Other designs were also considered.  Several possibilities have also
been discussed on python-dev in past years.

Alternatives include:

* use a high bit to mark "immortal" but do not change ``Py_INCREF()``
* add an explicit flag to objects
* implement via the type (``tp_dealloc()`` is a no-op)
* track via the object's type object
* track with a separate table

Each of the above makes objects immortal, but none of them address
the performance penalties from refcount modification described above.

In the case of per-interpreter GIL, the only realistic alternative
is to move all global objects into ``PyInterpreterState`` and add
one or more lookup functions to access them.  Then we'd have to
add some hacks to the C-API to preserve compatibility for the
may objects exposed there.  The story is much, much simpler
with immortal objects


Impact
======

Benefits
--------

Most notably, the cases described in the two examples above stand
to benefit greatly from immortal objects.  Projects using pre-fork
can drop their workarounds.  For the per-interpreter GIL project,
immortal objects greatly simplifies the solution for existing static
types, as well as objects exposed by the public C-API.

In general, a strong immutability guarantee for objects enables Python
applications to scale like never before.  This is because they can
then leverage multi-core parallelism without a tradeoff in memory
usage.  This is reflected in most of the above cases.

Performance
-----------

A naive implementation shows `a 4% slowdown`_.
Several promising mitigation strategies will be pursued in the effort
to bring it closer to performance-neutral.  See the `mitigation`_
section below.

On the positive side, immortal objects save a significant amount of
memory when used with a pre-fork model.  Also, immortal objects provide
opportunities for specialization in the eval loop that would improve
performance.

.. _a 4% slowdown: https://github.com/python/cpython/pull/19474#issuecomment-1032944709

Backward Compatibility
-----------------------

This proposal is meant to be completely compatible.  It focuses strictly
on internal implementation details.  It does not involve changes to any
public API, other a few minor changes in behavior related to refcounts
(but only for immortal objects):

* code that inspects the refcount will see a really, really large value
* the new noop behavior may break code that:

  * depends specifically on the refcount to always increment or decrement
    (or have a specific value from ``Py_SET_REFCNT()``)
  * relies on any specific refcount value, other than 0
  * directly manipulates the refcount to store extra information there

Again, those changes in behavior only apply to immortal objects, not
most of the objects a user will access.  Furthermore, users cannot mark
an object as immortal so no user-created objects will ever have that
changed behavior.  Users that rely on any of the changing behavior for
global (builtin) objects are already in trouble.

Also note that code which checks for refleaks should keep working fine,
unless it checks for hard-coded small values relative to some immortal
object.  The problems noticed by `Pyston`_ shouldn't apply here since
we do not modify the refcount.

See `scope`_ below for further discussion.

The approach is also compatible with extensions compiled to the stable
ABI.  Unfortunately, they will modify the refcount and invalidate all
the performance benefits of immortal objects.  However, the high bit
of the refcount `will still match _Py_IMMORTAL_REFCNT <_Py_IMMORTAL_REFCNT_>`_
so we can still identify such objects as immortal.  At worst, objects
in that situation would feel the effects described in the `Motivation`_
section.  Even then the overall impact is unlikely to be significant.

..
    >> What about extensions compiled with Python 3.11 (with this PEP) that use
    >> an older version of the stable ABI, and thus should be compatible with
    >> 3.2+? Will they use the old versions of the macros? How will that be tested?
    >
    > It wouldn't matter unless an object's refcount reached
    > _Py_IMMORTAL_REFCNT, at which point incref/decref would start
    > noop'ing.  What is the likelihood (in real code) that an object's
    > refcount would grow that far?  Even then, would such an object ever be
    > expected to go back to 0 (and be dealloc'ed)?  Otherwise the point is
    > moot.
    
    That's exactly the questions I'd hope the PEP to answer. I could
    estimate that likelihood myself, but I'd really rather just check your
    work ;)
    
    (Hm, maybe I couldn't even estimate this myself. The PEP doesn't say
    what the value of _Py_IMMORTAL_REFCNT is, and in the ref implementation
    a comment says "This can be safely changed to a smaller value".)

Alternate Python Implementations
--------------------------------

This proposal is CPython-specific.  However, it does relate to the
behavior of the C-API, which may affect other Python implementations.
Consequently, the effect of changed behavior described in
`Backward Compatibility`_ above also applies here (e.g. if another
implementation is tightly coupled to specific refcount values, other
than 0, or on exactly how refcounts change, then they may impacted).

Security Implications
---------------------

This feature has no known impact on security.

Maintainability
---------------

This is not a complex feature so it should not cause much mental
overhead for maintainers.  The basic implementation doesn't touch
much code so it should have much impact on maintainability.  There
may be some extra complexity due to performance penalty mitigation.
However, that should be limited to where we immortalize all
objects post-init and that code will be in one place.

Non-Obvious Consequences
------------------------

* immortal objects that hold references to other objects
  ("containers") effectively immortalize each contained item
* the same is true for objects held internally by other objects
  (e.g. ``PyTypeObject.tp_subclasses``)

..
    > So, do immortal lists immortalize values append()ed to them? (Can you
    > even have an immortal list?  Are there limits on what can be immortal?)
    
    We have no plans to do more than ever explicitly immortalize objects.
    So an immortal list is fine but it would have no effect on the
    immortality of items it contains, other than implicitly (since the
    list holds a reference to each item).
    
    In general, it would be best to only immortalize immutable objects.
    If we want to share any objects shared between threads without
    protection (e.g. per-interpreter GIL) then such objects must be
    immortal and immutable.  So lists and dicts, etc. couldn't be shared
    (assuming we can't prevent further mutation).
    
    However, for objects that will never be shared, it can be practical to
    make some of them immortal too.  For example, sys.modules is a
    per-interpreter dict that we do not expect to ever get freed until the
    corresponding interpreter is finalized.  By making it immortal, we no
    longer incur the extra overhead during incref/decref.
    
    We can apply this idea in the pursuit of getting back some of that 4%
    performance we lost.  At the end of runtime init we can mark *all*
    objects as immortal and avoid the extra cost in incref/decref.  We
    only need to worry about immutability with objects that we plan on
    sharing between threads without a GIL.
    
    (FYI, we still need to look closely at the impact of this approach on GC.)

* an immortal object's type is effectively immortal

..
    > Should this be enforced?
    
    There is nothing to enforce.  The object holds a reference to its type
    so the type will never be cleaned up as long as the immortal object
    isn't.  Hence the type of an immortal object is effectively immortal.
    We don't need the type to actually be marked as immortal.

* though extremely unlikely (and technically hard), any object could
  be incref'ed enough to reach ``_Py_IMMORTAL_REFCNT`` and then
  be treated as immortal

..
    > What would it take?
    
    Basically, you;d have to do it deliberately (e.g. incref the object in
    a tight loop).  Even with a tight loop it would take a long time to
    count up to 2^61 or whatever the chosen value is.


Specification
=============

The approach involves these fundamental changes:

* add `_Py_IMMORTAL_REFCNT`_ (the magic value) to the internal C-API
* update ``Py_INCREF()`` and ``Py_DECREF()`` to no-op for objects with
  the magic refcount (or its most significant bit)
* do the same for any other API that modifies the refcount
* stop modifying ``PyGC_Head`` for immortal GC objects ("containers")
* ensure that all immortal objects are cleaned up during
  runtime finalization

Then setting any object's refcount to ``_Py_IMMORTAL_REFCNT``
makes it immortal.

(There are other minor, internal changes which are not described here.)

Public Refcount Details
-----------------------

As part of this proposal, we must make sure that users can clearly
understand on which parts of the refcount behavior they can rely and
which are considered implementation details.  Specifically, they should
use the existing public refcount-related API and the only refcount value
with any meaning is 0.  All other values are considered "not 0".

Arguably, the existing refcount-related API should be modified to reflect
what we want users to expect.  Something like the following:

* ``Py_INCREF()`` -> ``Py_ACQUIRE_REF()`` (or only support ``Py_NewRef()``)
* ``Py_DECREF()`` -> ``Py_RELEASE_REF()``
* ``Py_REFCNT()`` -> ``Py_HAS_REFS()``
* ``Py_SET_REFCNT()`` -> ``Py_RESET_REFS()`` and ``Py_SET_NO_REFS()``

However, such a change is not a part of this proposal.  It is included
here to demonstrate the tighter focus for user expectations that would
benefit this change.

See `Documentation`_ for more details.

Constraints
-----------

* ensure that otherwise immutable objects can be truly immutable
* minimize performance penalty for normal Python use cases
* be careful when immortalizing objects that we don't actually expect
  to persist until runtime finalization.
* be careful when immortalizing objects that are not otherwise immutable

.. scope:

Scope of Changes
----------------

This is not meant to be a public feature but rather an internal one.
So the proposal does *not* including adding any new public C-API,
nor any Python API.  However, this does not prevent us from
adding (publicly accessible) private API to do things
like immortalize an object or tell if one
is immortal.

..
    >> This proposal is CPython-specific and, effectively, describes
    >> internal implementation details.
    >
    > I think that is a naïve statement. Refcounting is
    > implementation-specific, but it's hardly an *internal* detail.
    
    Sorry for any confusion.  I didn't mean to say that refcounting is an
    internal detail.  Rather, I was talking about how the proposed change
    in refcounting behavior doesn't affect any guaranteed/documented
    behavior, hence "internal".
    
    >> There is
    >> code that targets CPython specifically, and relies on the details.
    >
    > Could you elaborate?  Do you mean such code relies on specific refcount values?
    >
    >> The refcount has public getters and setters,
    >
    > Agreed.  However, what behavior do users expect and what guarantees do
    > we make?  Do we indicate how to interpret the refcount value they
    > receive?  What are the use cases under which a user would set an
    > object's refcount to a specific value?  Are users setting the refcount
    > of objects they did not create?
    
    That's what I hoped the PEP would tell me. Instead of simply claiming
    that there won't be issues, it should explain why we won't have any issues.
    
    >> and you need a pretty good
    >> grasp of the concept to write a C extension.
    >
    > I would not expect this to be affected by this PEP, except in cases
    > where users are checking/modifying refcounts for objects they did not
    > create (since none of their objects will be immortal).
    >
    >> I think that it's safe to assume that this will break people's code,
    >
    > Do you have some use case in mind, or an example?  From my perspective
    > I'm having a hard time seeing what this proposed change would break.
    
    IMO, the reasoning should start from the assumption that things will
    break, and explain why they won't (or why the breakage is acceptable).
    If the PEP simply tells me upfront that things will be OK, I have a hard
    time trusting it.
    
    IOW, it's clear you've thought about this a lot (especially after
    reading your replies here), but it's not clear from the PEP.
    That might be editorial nitpicking, if it wasn't for the fact that I
    want find any gaps in your research and reasoning, and invite everyone
    else to look for them as well.
    
    >> and this PEP should convince us that the breakage is worth it rather than
    >> dismiss the issue.
    >
    > Sorry, I didn't mean to be dismissive.  I agree that if there is
    > breakage this PEP must address it.

..
    >> This is not meant to be a public feature but rather an internal one.
    >> So the proposal does *not* including adding any new public C-API,
    >> nor any Python API.  However, this does not prevent us from
    >> adding (publicly accessible) private API to do things
    >> like immortalize an object or tell if one
    >> is immortal.
    > 
    > This is a public change.
    
    I agree that the change to the implementation of some public API is
    certainly public, as is the change in behavior for immortal objects,
    as is the potential <4% performance regression.  By "public feature" I
    was referring to immortal objects.  We are not exposing that to users,
    other than that they might notice some objects now have a really high
    refcount that does not change.
    
    > Py_INCREF increments the reference count.
    > Py_REFCNT gets the reference count.
    > For immortal objects, Py_INCREF will no longer function as documented in
    > 3.10, and Py_REFCNT can be used to witness it. Both are public API.
    
    You are right that "Increment the reference count for object o." (as
    documented) will not be true for an immortal object.  Instead it would
    be something like "indicate that there is an additional reference for
    object o".  I'll be sure to update the PEP, to add that change to the
    docs wording.
    
    Regardless, how important is that distinction?  If it matters then
    clearly this proposal needs to change.  As an exercise, we can
    consider one of the most used objects, None, and that we would make it
    immortal.  How would that impact users of Py_INCREF() and Py_REFCNT()?

..
    > Importantly, our system allows for the reference count of immortal objects to change, as long as it doesn't go below half of the original very-high value. So extension code with no concept of immortality will still update the reference counts of immortal objects, but this is fine. Because of this we haven't seen any issues with extension modules.
    
    As Guido noted, we are taking a similar approach for the sake of older
    extensions built with the limited API.  As a precaution, we start the
    refcount for immortal objects basically at _Py_IMMORTAL_REFCNT * 1.5.
    Then we only need to check the high bit of _Py_IMMORTAL_REFCNT to see
    if an object is immortal.
    
    > 
    > The small amount of compatibility challenges we've run into have been in testing code that checks for memory leaks. For example this code breaks on Pyston:
    > 
    > [snip]
    > 
    > This might work with this PEP, but we've also seen code that asserts that the refcount increases by a specific value, which I believe wouldn't.
    > 
    > For Pyston we've simply disabled these tests, figuring that our users still have CPython to test on. Personally I consider this breakage to be small, but I hadn't seen anyone mention the potential usage of sys.getrefcount() so I thought I'd bring it up.

..
    I suggest being a little more explicit (even blatant) that the particular details of:
    
    (1)  which subset of functionally immortal objects are marked as immortal
    (2)  how to mark something as immortal
    (3)  how to recognize something as immortal
    (4)  which memory-management activities are skipped or modified for immortal objects
    
    are not only Cpython-specific, but are also private implementation details that are expected to change in subsequent versions.
    
    Ideally, things like the interned string dictionary or the constants from a pyc file will be not merely immortal, but stored in an immortal-only memory page, so that they won't be flushed or CoW-ed when a nearby non-immortal object is modified.  Getting those details right will make a difference to performance, and you don't want to be locked in to the first draft.


Immortal Mutable Objects
------------------------

Many of the use cases for immortal objects center on immutability.
However, it may be appropriate for a mutable object (e.g. a dict) to be
marked as immortal.  For example, there may be sufficient guarantee
that the object won't actually be modified.

A particularly relevant case relates to mutable objects that we do
expect to be modified.  We may know that such an object will never be
released (until runtime finalization).  In that case we can mark the
object as immortal in order to avoid the extra overhead in
``Py_INCREF()`` and ``Py_DECREF()``.  However, unlike immutable immortal
objects, such an object still can't be shared between two threads, at
least not without a lock to guard modification (e.g. the GIL or some
granular lock).

_Py_IMMORTAL_REFCNT
-------------------

We will add two internal constants::
    #define _Py_IMMORTAL_BIT (1LL << (8 * sizeof(Py_ssize_t) - 4))
    #define _Py_IMMORTAL_REFCNT (_Py_IMMORTAL_BIT + (_Py_IMMORTAL_BIT / 2))

The refcount for immortal objects will be set to ``_Py_IMMORTAL_REFCNT``.
However, to check if an object is immortal we will compare its refcount
against just the bit::
    (op->ob_refcnt & _Py_IMMORTAL_BIT) != 0

The difference means that an immortal object will still be considered
immortal, even if somehow its refcount were modified (e.g. by an older
stable ABI extension).

Note that top two bits of the refcount are already reserved for other
uses.  That's why we are using the third top-most bit.

Affected API
------------

API that will now ignore immortal objects:

* (public) ``Py_INCREF()``
* (public) ``Py_DECREF()``
* (public) ``Py_SET_REFCNT()``
* (private) ``_Py_NewReference()``

API that exposes refcounts (unchanged but may now return large values):

* (public) ``Py_REFCNT()``
* (public) ``sys.getrefcount()``

(Note that ``_Py_RefTotal`` and ``sys.gettotalrefcount()``
will not be affected.)

Immortal Global Objects
-----------------------

The following objects will be made immortal:

* singletons (``None``, ``True``, ``False``, ``Ellipsis``, ``NotImplemented``)
* all static types (e.g. ``PyLong_Type``, ``PyExc_Exception``)
* all static objects in ``_PyRuntimeState.global_objects`` (e.g. identifiers,
  small ints)

There will likely be others we have not enumerated here.

..
    > How will the candidates be chosen?
    
    Any objects that we would expect to share globally (ergo otherwise
    immutable) will be made immortal.  That means the static types, the
    builtin singletons, the objects in _PyRuntimeState.global_objects,
    etc.

..
    > Should the intern dict be belonging to runtime, or (sub)interpreter?
    >
    > If the interned dict is belonging to runtime, all interned dict should
    > be immortal to be shared between subinterpreters.
    
    Excellent questions.  Making immutable objects immortal is relatively
    simple.  For the most part, mutable objects should not be shared
    between interpreters without protection (e.g. the GIL).  The interned
    dict isn't exposed to Python code or the C-API, so there's less risk,
    but it still wouldn't work without cleverness.  So it should be
    per-interpreter.  It would be nice if it were global though. :)

..
    > What about __subclasses__/tp_subclasses?
    
    That's one we'll have to deal with specially, e.g. for core static
    types we'd store the object on PyInterpreterState.  Then the
    __subclasses__ getter would do a lookup on the current interpreter,
    instead of using tp_subclasses.  We could get rid of tp_subclasses or
    perhaps use it only for the main interpreter.

Object Cleanup
--------------

In order to clean up all immortal objects during runtime finalization,
we must keep track of them.

For GC objects ("containers") we'll leverage the GC's permanent
generation by pushing all immortalized containers there.  During
runtime shutdown, the strategy will be to first let the runtime try
to do its best effort of deallocating these instances normally.  Most
of the module deallocation will now be handled by
``pylifecycle.c:finalize_modules()`` which cleans up the remaining
modules as best as we can.  It will change which modules are available
during __del__ but that's already defined as undefined behavior by the
docs.  Optionally, we could do some topological disorder to guarantee
that user modules will be deallocated first before the stdlib modules.
Finally, anything leftover (if any) can be found through the permanent
generation gc list which we can clear after finalize_modules().

For non-container objects, the tracking approach will vary on a
case-by-case basis.  In nearly every case, each such object is directly
accessible on the runtime state, e.g. in a ``_PyRuntimeState`` or
``PyInterpreterState`` field.  We may need to add a tracking mechanism
to the runtime state for a small number of objects.

.. mitigation:

Performance Regression Mitigation
---------------------------------

In the interest of clarify, here are some of the ways we are going
to try to recover some of the lost performance:

* ...

Note that these are not part of the proposal.  They are included here
for clarity.

Possible Changes
----------------

* mark every interned string as immortal
* mark the "interned" dict as immortal if shared else share all interned strings
* (Larry,MvL) mark all constants unmarshalled for a module as immortal
* (Larry,MvL) allocate (immutable) immortal objects in their own memory page(s)
* drop refcount operations in code where we know the object is immortal
  (e.g. ``Py_RETURN_NONE``)
* specialize for immortal objects in the eval loop (see `Pyston`_)

Documentation
-------------

The immortal objects behavior and API are internal, implementation
details and will not be added to the documentation.

However, we will update the documentation to make public guarantees
about refcount behavior more clear.  That includes, specifically:

* ``Py_INCREF()`` - change "Increment the reference count for object o."
  to "Acquire a new reference to object o."
* ``Py_DECREF()`` - change "Decrement the reference count for object o."
  to "Release a reference to object o."
* similar for ``Py_XINCREF()``, ``Py_XDECREF()``, ``Py_NewRef()``,
  ``Py_XNewRef()``, ``Py_Clear()``, ``Py_REFCNT()``, and ``Py_SET_REFCNT()``

We *may* also add a note about immortal objects to the following,
to help reduce any surprise users may have with the change:

* ``Py_SET_REFCNT()`` (a no-op for immortal objects)
* ``Py_REFCNT()`` (value may be surprisingly large)
* ``sys.getrefcount()`` (value may be surprisingly large)

Other API that might benefit from such notes are currently undocumented.
We wouldn't add such a note anywhere else (including for ``Py_INCREF()``
and ``Py_DECREF()``) since the feature is otherwise transparent to users.


Reference Implementation
========================

The implementation is proposed on GitHub:

https://github.com/python/cpython/pull/19474


Open Issues
===========

* is there any other impact on GC?


References
==========

.. _Pyston: https://mail.python.org/archives/list/python-dev@python.org/message/TPLEYDCXFQ4AMTW6F6OQFINSIFYBRFCR/

Discussions
-----------

This was discussed in December 2021 on python-dev:

* https://mail.python.org/archives/list/python-dev@python.org/thread/7O3FUA52QGTVDC6MDAV5WXKNFEDRK5D6/#TBTHSOI2XRWRO6WQOLUW3X7S5DUXFAOV
* https://mail.python.org/archives/list/python-dev@python.org/thread/PNLBJBNIQDMG2YYGPBCTGOKOAVXRBJWY

Runtime Object State
--------------------

Here is the internal state that the CPython runtime keeps
for each Python object:

* `PyObject.ob_refcnt`_: the object's `refcount <refcounting_>`_
* `_PyGC_Head`_: (optional) the object's node in a list of `"GC" objects <refcounting_>`_
* `_PyObject_HEAD_EXTRA`_: (optional) the object's node in the list of heap objects

``ob_refcnt`` is part of the memory allocated for every object.
However, ``_PyObject_HEAD_EXTRA`` is allocated only if CPython was built
with ``Py_TRACE_REFS`` defined.  ``PyGC_Head`` is allocated only if the
object's type has ``Py_TPFLAGS_HAVE_GC`` set.  Typically this is only
container types (e.g. ``list``).  Also note that ``PyObject.ob_refcnt``
and ``_PyObject_HEAD_EXTRA`` are part of ``PyObject_HEAD``.

.. _PyObject.ob_refcnt: https://github.com/python/cpython/blob/80a9ba537f1f1666a9e6c5eceef4683f86967a1f/Include/object.h#L107
.. _PyGC_Head: https://github.com/python/cpython/blob/80a9ba537f1f1666a9e6c5eceef4683f86967a1f/Include/internal/pycore_gc.h#L11-L20
.. __PyObject_HEAD_EXTRA: https://github.com/python/cpython/blob/80a9ba537f1f1666a9e6c5eceef4683f86967a1f/Include/object.h#L68-L72

.. _refcounting:

Reference Counting, with Cyclic Garbage Collection
--------------------------------------------------

Garbage collection is a memory management feature of some programming
languages.  It means objects are cleaned up (e.g. memory freed)
once they are no longer used.

Refcounting is one approach to garbage collection.  The language runtime
tracks how many references are held to an object.  When code takes
ownership of a reference to an object or releases it, the runtime
is notified and it increments or decrements the refcount accordingly.
When the refcount reaches 0, the runtime cleans up the object.

With CPython, code must explicitly take or release references using
the C-API's ``Py_INCREF()`` and ``Py_DECREF()``.  These macros happen
to directly modify the object's refcount (unfortunately, since that
causes ABI compatibility issues if we want to change our garbage
collection scheme).  Also, when an object is cleaned up in CPython,
it also releases any references (and resources) it owns
(before it's memory is freed).

Sometimes objects may be involved in reference cycles, e.g. where
object A holds a reference to object B and object B holds a reference
to object A.  Consequently, neither object would ever be cleaned up
even if no other references were held (i.e. a memory leak).  The
most common objects involved in cycles are containers.

CPython has dedicated machinery to deal with reference cycles, which
we call the "cyclic garbage collector", or often just
"garbage collector" or "GC".  Don't let the name confuse you.
It only deals with breaking reference cycles.

See the docs for a more detailed explanation of refcounting
and cyclic garbage collection:

* https://docs.python.org/3.11/c-api/intro.html#reference-counts
* https://docs.python.org/3.11/c-api/refcounting.html
* https://docs.python.org/3.11/c-api/typeobj.html#c.PyObject.ob_refcnt
* https://docs.python.org/3.11/c-api/gcsupport.html


Copyright
=========

This document is placed in the public domain or under the
CC0-1.0-Universal license, whichever is more permissive.



..
    Local Variables:
    mode: indented-text
    indent-tabs-mode: nil
    sentence-end-double-space: t
    fill-column: 70
    coding: utf-8
    End:
